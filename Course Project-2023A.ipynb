{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Name:** HUANG Shaohang\n",
    "\n",
    "**EIDs:** shuang293\n",
    "\n",
    "**Kaggle Competition:** \\_\\_\\_\\_\n",
    "\n",
    "**Kaggle Team Name:** \\_\\_\\_\\_\\_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Course Project (2023A)\n",
    "\n",
    "Due date: See canvas site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Projects\n",
    "\n",
    "For the course project, you may select **one** of the following competitions on Kaggle **or** define your own course project:\n",
    "\n",
    "### [LLM - Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text): Identify which essay was written by a large language model\n",
    "\n",
    ">In recent years, large language models (LLMs) have become increasingly sophisticated, capable of generating text that is difficult to distinguish from human-written text. In this competition, we hope to foster open research and transparency on AI detection techniques applicable in the real world.\n",
    ">\n",
    ">This competition challenges participants to develop a machine learning model that can accurately detect whether an essay was written by a student or an LLM. The competition dataset comprises a mix of student-written essays and essays generated by a variety of LLMs.\n",
    "\n",
    "### [Optiver - Trading at the Close](https://www.kaggle.com/competitions/optiver-trading-at-the-close): Predict US stocks closing movements\n",
    "\n",
    ">In this competition, you are challenged to develop a model capable of predicting the closing price movements for hundreds of Nasdaq listed stocks using data from the order book and the closing auction of the stock. Information from the auction can be used to adjust prices, assess supply and demand dynamics, and identify trading opportunities.\n",
    "\n",
    "### [Linking Writing Processes to Writing Quality](https://www.kaggle.com/competitions/linking-writing-processes-to-writing-quality): Use typing behavior to predict essay quality identify which essay was written by a large language model\n",
    "\n",
    ">The goal of this competition is to predict overall writing quality. Does typing behavior affect the outcome of an essay? You will develop a model trained on a large dataset of keystroke logs that have captured writing process features.\n",
    ">\n",
    ">Your work will help explore the relationship between learnersâ€™ writing behaviors and writing performance, which could provide valuable insights for writing instruction, the development of automated writing evaluation techniques, and intelligent tutoring systems.\n",
    "\n",
    "### [Child Mind Institute - Detect Sleep States](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states): Detect sleep onset and wake from wrist-worn accelerometer data\n",
    "\n",
    "> Your work will improve researchers' ability to analyze accelerometer data for sleep monitoring and enable them to conduct large-scale studies of sleep. Ultimately, the work of this competition could improve awareness and guidance surrounding the importance of sleep. The valuable insights into how environmental factors impact sleep, mood, and behavior can inform the development of personalized interventions and support systems tailored to the unique needs of each child.\n",
    "\n",
    "\n",
    "### [Enefit - Predict Energy Behavior of Prosumers](https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers): Predict Prosumer Energy Patterns and Minimize Imbalance Costs.\n",
    "\n",
    "> The goal of the competition is to create an energy prediction model of prosumers to reduce energy imbalance costs.\n",
    ">\n",
    "> This competition aims to tackle the issue of energy imbalance, a situation where the energy expected to be used doesn't line up with the actual energy used or produced. Prosumers, who both consume and generate energy, contribute a large part of the energy imbalance. Despite being only a small part of all consumers, their unpredictable energy use causes logistical and financial problems for the energy companies.\n",
    "\n",
    "\n",
    "### Student-defined Course Project \n",
    "\n",
    "The goal of the student-defined project is to get some hands-on experience using the course material on your own research problems. Keep in mind that there will only be about 4 weeks to do the project, so the scope should not be too large. Following the major themes of the course, here are some general topics for the project:\n",
    "- _regression_ (supervised learning) - use regression methods (e.g. ridge regression, Gaussian processes) to model data or predict from data.\n",
    "- _classification_ (supervised learning) - use classification methods (e.g., SVM, BDR, Logistic Regression, NNs) to learn to distinguish between multiple classes given a feature vector.\n",
    "- _clustering_ (unsupervised learning) - use clustering methods (e.g., K-means, EM, Mean-Shift) to discover the natural groups in data.\n",
    "- _visualization_ (unsupervised learning) - use dimensionality reduction methods (e.g., PCA, kernel-PCA, non-linear embedding) to visualize the structure of high-dimensional data.\n",
    " \n",
    "You can pick any one of these topics and apply them to your own problem/data. \n",
    "\n",
    "- *Can my project be my recently submitted or soon-to-be submitted paper?* If you plan to just\n",
    "turn in the results from your paper, then the answer is no. The project cannot be be work\n",
    "that you have already done. However, your course project can be based on extending your\n",
    "work. For example, you can try some models introduced in the course on your data/problem.\n",
    "\n",
    "Before actually doing the project, you need to write a **project proposal** so that we can make sure the project is doable within the 3-4 weeks. I can also give you some pointers to relevant methods, if necessary.  \n",
    "- The project proposal should be at most one page with the following contents: 1) an introduction that briefy states the problem; 2) a precise description of what you plan to do - e.g., What types of features do you plan to use? What algorithms do you plan to use? What dataset will you use? How will you evaluate your results? How do you define a good outcome for the project?\n",
    "- The goal of the proposal is to work out, in your head, what your project will be. Once the proposal is done, it is just a matter of implementation!\n",
    "- *You need to submit the project proposal to Canvas 1 week after the Course project is released.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups\n",
    "Group projects should contain 2 students.  To sign up for a group, go to Canvas and under \"People\", join an existing **\"Project Group X\"**, where X is a number.  _For group projects, the project report must state the percentage contribution from each project member. You must also submit the contribution percentages to the \"Project Group Contribution\" assignment on Canvas._\n",
    "\n",
    "## Methodology\n",
    "You are free to choose the methodology to solve the task.  In machine learning, it is important to use domain knowledge to help solve the problem.  Hence, instead of blindly applying the algorithms to the data you need to think about how to represent the data in a way that makes sense for the algorithm to solve the task. \n",
    "\n",
    "## Kaggle: Kaggle Notebooks\n",
    "\n",
    "The Kaggle competitions have Kaggle Notebooks enabled, which provide free GPU/TPU computing resources (up to a limit).  You can develop your model in the Kaggle Notebook, CS5489 JupyterHub (Dive), or on your own computers.\n",
    "\n",
    "## Kaggle: Evaluation on Kaggle\n",
    "\n",
    "For Kaggle projects, the final evaluation will be performed on Kaggle. Note that for these competitions you need to submit your code via the Kaggle Notebook, which will then generate the submission file for processing. \n",
    "\n",
    "## Project Presentation\n",
    "\n",
    "Each project group needs to give a presentation at the end of the semester.  You will record your presentation and upload it to FlipGrid.  The presentation is limited to 5 minutes.  You _must_ give a presentation. See the details in the \"Project Presentations\" Canvas assignment.\n",
    "\n",
    "## What to hand in\n",
    "\n",
    "You need to turn in the following things.\n",
    "\n",
    "The following files should be uploaded to \"Course Project\" on Canvas:\n",
    "\n",
    "1. This ipynb file `CourseProject-2023A.ipynb` with your source code and documentation. **You should write about all the various attempts that you make to find a good solution.** You may also submit .py files, but your documentation should be in the ipynb file.\n",
    "2. A **PDF** version of your ipynb file.\n",
    "3. Presentation slides.\n",
    "4. (Kaggle projects) Your final submission file to Kaggle. Note that most competitions require you to submit the code, and Kaggle will run it on the hidden test set.\n",
    "5. (Kaggle projects) A downloaded copy of your Kaggle Notebook that is submitted to Kaggle. This file should contain the code that generates the final submission file on Kaggle. This code will be used to verify that your Kaggle submission is reproducible.\n",
    "\n",
    "Other things that need to be turned in:\n",
    "- Upload your Project presentation to FlipGrid and the submit the URL to the \"Project Presentations\" assignment on Canvas.  See the detailed instructions in the assignment.\n",
    "- Enter the percentage contribution for each project member using the \"Project Group Contribution\" assignment on Canvas.\n",
    "- (Student-defined projects only) submit your project proposal to the \"Project Proposal\" assignment on Canvas. The project proposal is due 1 week after the course project is released. Kaggle projects do not need to submit a proposal.\n",
    "\n",
    "\n",
    "\n",
    "## Grading\n",
    "The marks of the assignment are distributed as follows:\n",
    "- 40% - Results using various feature representations, dimensionality reduction methods, classifiers, etc.\n",
    "- 25% - Trying out feature representations (e.g. adding additional features, combining features from different sources) or methods not used in the tutorials.\n",
    "- 15% - Quality of the written report.  More points for insightful observations and analysis.\n",
    "- 15% - Project presentation\n",
    "- 5% - For Kaggle projects, final ranking on the Kaggle leaderboard;  For student-defined projects, the project proposal.\n",
    "\n",
    "**Late Penalty:** 25 marks will be subtracted for each day late.\n",
    "\n",
    "**Group contribution:** marks for a group member with less than equal contribution will be deducted according to the following formula:\n",
    "- Let A% and B% be the percentage contributions for group members Alice and Bob. A%+B%=100%\n",
    "- Let x be the group project marks.\n",
    "- If A>B, then Bob's marks will be reduced to be: x*B/A\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR METHODS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>down_time</th>\n",
       "      <th>up_time</th>\n",
       "      <th>action_time</th>\n",
       "      <th>activity</th>\n",
       "      <th>down_event</th>\n",
       "      <th>up_event</th>\n",
       "      <th>text_change</th>\n",
       "      <th>cursor_position</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>1</td>\n",
       "      <td>338433</td>\n",
       "      <td>338518</td>\n",
       "      <td>85</td>\n",
       "      <td>Input</td>\n",
       "      <td>Space</td>\n",
       "      <td>Space</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2</td>\n",
       "      <td>760073</td>\n",
       "      <td>760160</td>\n",
       "      <td>87</td>\n",
       "      <td>Input</td>\n",
       "      <td>Space</td>\n",
       "      <td>Space</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1</td>\n",
       "      <td>711956</td>\n",
       "      <td>712023</td>\n",
       "      <td>67</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>2</td>\n",
       "      <td>290502</td>\n",
       "      <td>290548</td>\n",
       "      <td>46</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1</td>\n",
       "      <td>635547</td>\n",
       "      <td>635641</td>\n",
       "      <td>94</td>\n",
       "      <td>Input</td>\n",
       "      <td>Space</td>\n",
       "      <td>Space</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  event_id  down_time  up_time  action_time activity down_event  \\\n",
       "0  0000aaaa         1     338433   338518           85    Input      Space   \n",
       "1  0000aaaa         2     760073   760160           87    Input      Space   \n",
       "2  2222bbbb         1     711956   712023           67    Input          q   \n",
       "3  2222bbbb         2     290502   290548           46    Input          q   \n",
       "4  4444cccc         1     635547   635641           94    Input      Space   \n",
       "\n",
       "  up_event text_change  cursor_position  word_count  \n",
       "0    Space                            0           0  \n",
       "1    Space                            1           0  \n",
       "2        q           q                0           1  \n",
       "3        q           q                1           1  \n",
       "4    Space                            0           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logs = pd.read_csv('train_logs.csv')\n",
    "test_logs = pd.read_csv('test_logs.csv')\n",
    "train_scores = pd.read_csv('train_scores.csv')\n",
    "test_logs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see each data record presents an operation of a session, and the letters are anonymized. The data is already sorted by session id and timestamp.\n",
    "\n",
    "Considering the letters are anonymized, I don't think we should restore the article. So I will just use the data as it is.\n",
    "\n",
    "We can count the number of sessions and the number of operations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_cnt</th>\n",
       "      <th>op_time_avg</th>\n",
       "      <th>input_cnt</th>\n",
       "      <th>q_cnt</th>\n",
       "      <th>Space_cnt</th>\n",
       "      <th>Backspace_cnt</th>\n",
       "      <th>Shift_cnt</th>\n",
       "      <th>ArrowRight_cnt</th>\n",
       "      <th>Leftclick_cnt</th>\n",
       "      <th>ArrowLeft_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>,_cnt</th>\n",
       "      <th>ArrowDown_cnt</th>\n",
       "      <th>ArrowUp_cnt</th>\n",
       "      <th>Enter_cnt</th>\n",
       "      <th>CapsLock_cnt</th>\n",
       "      <th>'_cnt</th>\n",
       "      <th>Delete_cnt</th>\n",
       "      <th>Unidentified_cnt</th>\n",
       "      <th>word_cnt</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001519c8</th>\n",
       "      <td>2557</td>\n",
       "      <td>116.246774</td>\n",
       "      <td>2010</td>\n",
       "      <td>1619</td>\n",
       "      <td>357</td>\n",
       "      <td>417.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255</td>\n",
       "      <td>1797443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0022f953</th>\n",
       "      <td>2454</td>\n",
       "      <td>112.221271</td>\n",
       "      <td>1938</td>\n",
       "      <td>1490</td>\n",
       "      <td>391</td>\n",
       "      <td>260.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320</td>\n",
       "      <td>1758346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0042269b</th>\n",
       "      <td>4136</td>\n",
       "      <td>101.837766</td>\n",
       "      <td>3515</td>\n",
       "      <td>2904</td>\n",
       "      <td>552</td>\n",
       "      <td>439.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404</td>\n",
       "      <td>1767228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0059420b</th>\n",
       "      <td>1556</td>\n",
       "      <td>121.848329</td>\n",
       "      <td>1304</td>\n",
       "      <td>1038</td>\n",
       "      <td>243</td>\n",
       "      <td>152.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206</td>\n",
       "      <td>1363074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0075873a</th>\n",
       "      <td>2531</td>\n",
       "      <td>123.943896</td>\n",
       "      <td>1942</td>\n",
       "      <td>1541</td>\n",
       "      <td>324</td>\n",
       "      <td>517.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252</td>\n",
       "      <td>1584002.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          op_cnt  op_time_avg  input_cnt  q_cnt  Space_cnt  Backspace_cnt  \\\n",
       "id                                                                          \n",
       "001519c8    2557   116.246774       2010   1619        357          417.0   \n",
       "0022f953    2454   112.221271       1938   1490        391          260.0   \n",
       "0042269b    4136   101.837766       3515   2904        552          439.0   \n",
       "0059420b    1556   121.848329       1304   1038        243          152.0   \n",
       "0075873a    2531   123.943896       1942   1541        324          517.0   \n",
       "\n",
       "          Shift_cnt  ArrowRight_cnt  Leftclick_cnt  ArrowLeft_cnt  ...  ,_cnt  \\\n",
       "id                                                                 ...          \n",
       "001519c8       27.0             2.0           92.0            2.0  ...   12.0   \n",
       "0022f953       97.0            46.0           56.0           49.0  ...   21.0   \n",
       "0042269b       39.0             6.0          129.0            NaN  ...   23.0   \n",
       "0059420b       68.0             NaN           18.0            NaN  ...    3.0   \n",
       "0075873a       39.0             NaN           33.0            NaN  ...   24.0   \n",
       "\n",
       "          ArrowDown_cnt  ArrowUp_cnt  Enter_cnt  CapsLock_cnt  '_cnt  \\\n",
       "id                                                                     \n",
       "001519c8            NaN          NaN        4.0           NaN    3.0   \n",
       "0022f953            3.0          2.0        6.0           NaN    3.0   \n",
       "0042269b            NaN          NaN       17.0           NaN    NaN   \n",
       "0059420b            NaN          NaN        3.0           2.0    2.0   \n",
       "0075873a            NaN          NaN       10.0           NaN   17.0   \n",
       "\n",
       "          Delete_cnt  Unidentified_cnt  word_cnt  total_time  \n",
       "id                                                            \n",
       "001519c8         NaN               NaN       255   1797443.0  \n",
       "0022f953         NaN               NaN       320   1758346.0  \n",
       "0042269b         NaN               NaN       404   1767228.0  \n",
       "0059420b         NaN               NaN       206   1363074.0  \n",
       "0075873a         NaN               NaN       252   1584002.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_representation = pd.DataFrame()\n",
    "test_data_representation = pd.DataFrame()\n",
    "\n",
    "train_data_representation['op_cnt'] = train_logs.groupby('id')['event_id'].count()\n",
    "train_data_representation['op_time_avg'] = train_logs.groupby('id')['action_time'].mean()\n",
    "train_data_representation['input_cnt'] = train_logs[train_logs['activity'] == 'Input'].groupby('id')['event_id'].count()\n",
    "train_data_representation['q_cnt'] = train_logs[train_logs['down_event'] == 'q'].groupby('id')['event_id'].count()\n",
    "\n",
    "# add word_cnt column\n",
    "train_data_representation['word_cnt'] = 0\n",
    "i = -1\n",
    "for index, row in train_data_representation.iterrows():\n",
    "    start_time = train_logs.loc[int(i+1)]['down_time']\n",
    "    i += row['op_cnt']\n",
    "    end_time = train_logs.loc[int(i)]['up_time']\n",
    "    train_data_representation.loc[index, 'word_cnt'] = train_logs.loc[int(i)]['word_count']\n",
    "    train_data_representation.loc[index, 'total_time'] = (end_time - start_time)\n",
    "\n",
    "test_data_representation['op_cnt'] = test_logs.groupby('id')['event_id'].count()\n",
    "test_data_representation['op_time_avg'] = test_logs.groupby('id')['action_time'].mean()\n",
    "test_data_representation['input_cnt'] = test_logs[test_logs['activity'] == 'Input'].groupby('id')['event_id'].count()\n",
    "test_data_representation['q_cnt'] = test_logs[test_logs['down_event'] == 'q'].groupby('id')['event_id'].count()\n",
    "# add word_cnt column\n",
    "test_data_representation['word_cnt'] = 0\n",
    "i = -1\n",
    "for index, row in test_data_representation.iterrows():\n",
    "    start_time = test_logs.loc[int(i+1)]['down_time']\n",
    "    i += row['op_cnt']\n",
    "    end_time = test_logs.loc[int(i)]['up_time']\n",
    "    test_data_representation.loc[index, 'word_cnt'] = test_logs.loc[int(i)]['word_count']\n",
    "    test_data_representation.loc[index, 'total_time'] = (end_time - start_time)\n",
    "\n",
    "\n",
    "train_data_representation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = train_scores['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data_normalized = scaler.fit_transform(train_data_representation)\n",
    "test_data_normalized = scaler.transform(test_data_representation)\n",
    "train_data_normalized = np.nan_to_num(train_data_normalized)\n",
    "test_data_normalized = np.nan_to_num(test_data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of linear models may not be good, but we can use them as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value for Ridge Regression:  0.1\n",
      "RMSE for Ridge Regression:  0.7404481909377503\n"
     ]
    }
   ],
   "source": [
    "# ridge regression\n",
    "alphas = logspace(-6, -1, 100)\n",
    "rr = linear_model.RidgeCV(alphas=alphas, cv=5)\n",
    "rr.fit(train_data_normalized, trainY)\n",
    "\n",
    "# print the RMSE for the best alpha value\n",
    "print(\"Best alpha value for Ridge Regression: \", rr.alpha_)\n",
    "print(\"RMSE for Ridge Regression: \", sqrt(metrics.mean_squared_error(trainY, rr.predict(train_data_normalized))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for OLS Regression:  0.7398187010686172\n"
     ]
    }
   ],
   "source": [
    "# ols regression\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(train_data_normalized, trainY)\n",
    "\n",
    "# print the RMSE for the best alpha value\n",
    "print(\"RMSE for OLS Regression: \", sqrt(metrics.mean_squared_error(trainY, ols.predict(train_data_normalized))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel RR Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value for Kernel Ridge Regression:  {'alpha': 0.01, 'gamma': 0.21544346900318823}\n",
      "RMSE for Kernel Ridge Regression:  0.6466704776781056\n"
     ]
    }
   ],
   "source": [
    "paramgrid = {'alpha': logspace(-6, 0, 10), \n",
    "             'gamma': logspace(-6, 0, 10)}\n",
    "\n",
    "krrcv = model_selection.GridSearchCV(estimator=kernel_ridge.KernelRidge(kernel='rbf'),\n",
    "                                        param_grid=paramgrid, cv=5)\n",
    "krrcv.fit(train_data_normalized, trainY)\n",
    "\n",
    "# print the RMSE for the best alpha value\n",
    "print(\"Best alpha value for Kernel Ridge Regression: \", krrcv.best_params_)\n",
    "print(\"RMSE for Kernel Ridge Regression: \", sqrt(metrics.mean_squared_error(trainY, krrcv.predict(train_data_normalized))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than linear models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value for Support Vector Regression:  {'C': 10.0, 'gamma': 1.0}\n",
      "RMSE for Support Vector Regression:  0.6362888479019606\n"
     ]
    }
   ],
   "source": [
    "paramgrid = {'C': logspace(-3, 3, 7), \n",
    "             'gamma': logspace(-3, 3, 7)}\n",
    "\n",
    "svrcv = model_selection.GridSearchCV(estimator=svm.SVR(kernel='rbf'),\n",
    "                                        param_grid=paramgrid, cv=5)\n",
    "svrcv.fit(train_data_normalized, trainY)\n",
    "\n",
    "# print the RMSE for the best alpha value\n",
    "print(\"Best alpha value for Support Vector Regression: \", svrcv.best_params_)\n",
    "print(\"RMSE for Support Vector Regression: \", sqrt(metrics.mean_squared_error(trainY, svrcv.predict(train_data_normalized))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the scores are all 0.5 times a integer. So we can try classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3.5: 0, 6.0: 1, 2.0: 2, 4.0: 3, 4.5: 4, 2.5: 5, 5.0: 6, 3.0: 7, 1.5: 8, 5.5: 9, 1.0: 10, 0.5: 11}\n",
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       2\n",
      "4       3\n",
      "       ..\n",
      "2466    0\n",
      "2467    3\n",
      "2468    8\n",
      "2469    6\n",
      "2470    3\n",
      "Name: score, Length: 2471, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# turn the scores into labels\n",
    "tags = train_scores['score'].unique()\n",
    "\n",
    "label_nums = {tag: num for num, tag in enumerate(tags)}\n",
    "print(label_nums)\n",
    "\n",
    "trainY_labels = train_scores['score'].map(label_nums)\n",
    "print(trainY_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               5632      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,260\n",
      "Trainable params: 49,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.2322 - accuracy: 0.1867 - val_loss: 2.1353 - val_accuracy: 0.2081\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1294 - accuracy: 0.1893 - val_loss: 2.1200 - val_accuracy: 0.2343\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1248 - accuracy: 0.1953 - val_loss: 2.1181 - val_accuracy: 0.2343\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1234 - accuracy: 0.1959 - val_loss: 2.1219 - val_accuracy: 0.2343\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 2.1238 - accuracy: 0.1857 - val_loss: 2.1225 - val_accuracy: 0.2343\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1232 - accuracy: 0.1807 - val_loss: 2.1156 - val_accuracy: 0.2343\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1220 - accuracy: 0.1857 - val_loss: 2.1099 - val_accuracy: 0.2343\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1219 - accuracy: 0.1938 - val_loss: 2.1228 - val_accuracy: 0.2081\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1216 - accuracy: 0.1928 - val_loss: 2.1111 - val_accuracy: 0.2081\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1203 - accuracy: 0.1938 - val_loss: 2.1194 - val_accuracy: 0.2182\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 2.1140 - accuracy: 0.1994 - val_loss: 2.0942 - val_accuracy: 0.2586\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.0639 - accuracy: 0.2227 - val_loss: 2.0131 - val_accuracy: 0.2323\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.9485 - accuracy: 0.2869 - val_loss: 1.9371 - val_accuracy: 0.2747\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.8764 - accuracy: 0.3021 - val_loss: 1.8966 - val_accuracy: 0.2444\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.8471 - accuracy: 0.2854 - val_loss: 1.9288 - val_accuracy: 0.2505\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.8308 - accuracy: 0.2996 - val_loss: 1.8625 - val_accuracy: 0.2747\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.8059 - accuracy: 0.3133 - val_loss: 1.8467 - val_accuracy: 0.2889\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7871 - accuracy: 0.3203 - val_loss: 1.8221 - val_accuracy: 0.2768\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7769 - accuracy: 0.3153 - val_loss: 1.8310 - val_accuracy: 0.2606\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7720 - accuracy: 0.3133 - val_loss: 1.8143 - val_accuracy: 0.2768\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7640 - accuracy: 0.3077 - val_loss: 1.8097 - val_accuracy: 0.2788\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7567 - accuracy: 0.3143 - val_loss: 1.8141 - val_accuracy: 0.2687\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7560 - accuracy: 0.3117 - val_loss: 1.8290 - val_accuracy: 0.3010\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7554 - accuracy: 0.3072 - val_loss: 1.8080 - val_accuracy: 0.2667\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7472 - accuracy: 0.3219 - val_loss: 1.8050 - val_accuracy: 0.2727\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7478 - accuracy: 0.3112 - val_loss: 1.8083 - val_accuracy: 0.2606\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7433 - accuracy: 0.3193 - val_loss: 1.8278 - val_accuracy: 0.2869\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7436 - accuracy: 0.3269 - val_loss: 1.8242 - val_accuracy: 0.3071\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7396 - accuracy: 0.3092 - val_loss: 1.7933 - val_accuracy: 0.2828\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7427 - accuracy: 0.3289 - val_loss: 1.7979 - val_accuracy: 0.2707\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7349 - accuracy: 0.3259 - val_loss: 1.8030 - val_accuracy: 0.3071\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7364 - accuracy: 0.3178 - val_loss: 1.8081 - val_accuracy: 0.2869\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7311 - accuracy: 0.3183 - val_loss: 1.8022 - val_accuracy: 0.2707\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7334 - accuracy: 0.3133 - val_loss: 1.7915 - val_accuracy: 0.2848\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7328 - accuracy: 0.3289 - val_loss: 1.8069 - val_accuracy: 0.2727\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7337 - accuracy: 0.3269 - val_loss: 1.7941 - val_accuracy: 0.2747\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7311 - accuracy: 0.3229 - val_loss: 1.8025 - val_accuracy: 0.2646\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7331 - accuracy: 0.3193 - val_loss: 1.8156 - val_accuracy: 0.2788\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7276 - accuracy: 0.3345 - val_loss: 1.8320 - val_accuracy: 0.2828\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7341 - accuracy: 0.3289 - val_loss: 1.7985 - val_accuracy: 0.2990\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7303 - accuracy: 0.3198 - val_loss: 1.8111 - val_accuracy: 0.3030\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7336 - accuracy: 0.3163 - val_loss: 1.7941 - val_accuracy: 0.3071\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7289 - accuracy: 0.3330 - val_loss: 1.7929 - val_accuracy: 0.2727\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7282 - accuracy: 0.3234 - val_loss: 1.7939 - val_accuracy: 0.2707\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7249 - accuracy: 0.3214 - val_loss: 1.7942 - val_accuracy: 0.2909\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7244 - accuracy: 0.3209 - val_loss: 1.7861 - val_accuracy: 0.2929\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7233 - accuracy: 0.3295 - val_loss: 1.7841 - val_accuracy: 0.2828\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7268 - accuracy: 0.3244 - val_loss: 1.8141 - val_accuracy: 0.3071\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7243 - accuracy: 0.3310 - val_loss: 1.7879 - val_accuracy: 0.2828\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7208 - accuracy: 0.3325 - val_loss: 1.7882 - val_accuracy: 0.2828\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7167 - accuracy: 0.3274 - val_loss: 1.7879 - val_accuracy: 0.2788\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7213 - accuracy: 0.3310 - val_loss: 1.7881 - val_accuracy: 0.2909\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7285 - accuracy: 0.3254 - val_loss: 1.7834 - val_accuracy: 0.2828\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7176 - accuracy: 0.3279 - val_loss: 1.7914 - val_accuracy: 0.2889\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7243 - accuracy: 0.3234 - val_loss: 1.7968 - val_accuracy: 0.3030\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7215 - accuracy: 0.3244 - val_loss: 1.7868 - val_accuracy: 0.2889\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7191 - accuracy: 0.3249 - val_loss: 1.7835 - val_accuracy: 0.2869\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7211 - accuracy: 0.3325 - val_loss: 1.7850 - val_accuracy: 0.2970\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7184 - accuracy: 0.3310 - val_loss: 1.7840 - val_accuracy: 0.2747\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7204 - accuracy: 0.3219 - val_loss: 1.7846 - val_accuracy: 0.2949\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7215 - accuracy: 0.3269 - val_loss: 1.8148 - val_accuracy: 0.3131\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.7238 - accuracy: 0.3264 - val_loss: 1.7787 - val_accuracy: 0.2909\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7249 - accuracy: 0.3274 - val_loss: 1.7811 - val_accuracy: 0.2747\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7176 - accuracy: 0.3289 - val_loss: 1.7861 - val_accuracy: 0.2828\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7226 - accuracy: 0.3365 - val_loss: 1.7903 - val_accuracy: 0.3192\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7155 - accuracy: 0.3254 - val_loss: 1.7852 - val_accuracy: 0.2970\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7154 - accuracy: 0.3345 - val_loss: 1.7949 - val_accuracy: 0.2990\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7208 - accuracy: 0.3284 - val_loss: 1.7900 - val_accuracy: 0.2727\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7231 - accuracy: 0.3198 - val_loss: 1.7931 - val_accuracy: 0.3010\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7164 - accuracy: 0.3289 - val_loss: 1.7961 - val_accuracy: 0.2828\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7227 - accuracy: 0.3254 - val_loss: 1.7784 - val_accuracy: 0.2889\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7163 - accuracy: 0.3350 - val_loss: 1.7806 - val_accuracy: 0.2990\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7195 - accuracy: 0.3229 - val_loss: 1.8024 - val_accuracy: 0.3152\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7157 - accuracy: 0.3244 - val_loss: 1.7841 - val_accuracy: 0.3051\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7152 - accuracy: 0.3249 - val_loss: 1.7786 - val_accuracy: 0.2848\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7150 - accuracy: 0.3310 - val_loss: 1.7756 - val_accuracy: 0.2848\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7129 - accuracy: 0.3335 - val_loss: 1.7827 - val_accuracy: 0.2828\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7135 - accuracy: 0.3259 - val_loss: 1.7844 - val_accuracy: 0.2707\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7202 - accuracy: 0.3300 - val_loss: 1.7853 - val_accuracy: 0.2667\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7121 - accuracy: 0.3279 - val_loss: 1.7744 - val_accuracy: 0.2949\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7122 - accuracy: 0.3259 - val_loss: 1.7866 - val_accuracy: 0.2848\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7107 - accuracy: 0.3289 - val_loss: 1.7790 - val_accuracy: 0.3030\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7165 - accuracy: 0.3249 - val_loss: 1.7854 - val_accuracy: 0.2848\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7146 - accuracy: 0.3264 - val_loss: 1.7899 - val_accuracy: 0.2869\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7146 - accuracy: 0.3269 - val_loss: 1.7803 - val_accuracy: 0.2990\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7093 - accuracy: 0.3360 - val_loss: 1.7860 - val_accuracy: 0.2970\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7140 - accuracy: 0.3259 - val_loss: 1.7773 - val_accuracy: 0.2889\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7107 - accuracy: 0.3279 - val_loss: 1.7781 - val_accuracy: 0.2768\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7133 - accuracy: 0.3264 - val_loss: 1.7767 - val_accuracy: 0.3010\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7129 - accuracy: 0.3320 - val_loss: 1.7768 - val_accuracy: 0.3051\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7157 - accuracy: 0.3203 - val_loss: 1.7725 - val_accuracy: 0.2909\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7113 - accuracy: 0.3254 - val_loss: 1.7733 - val_accuracy: 0.3232\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7140 - accuracy: 0.3320 - val_loss: 1.7771 - val_accuracy: 0.2990\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7132 - accuracy: 0.3229 - val_loss: 1.7770 - val_accuracy: 0.2949\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7115 - accuracy: 0.3310 - val_loss: 1.7769 - val_accuracy: 0.2929\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7101 - accuracy: 0.3391 - val_loss: 1.7996 - val_accuracy: 0.2909\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7117 - accuracy: 0.3219 - val_loss: 1.7745 - val_accuracy: 0.2929\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7164 - accuracy: 0.3259 - val_loss: 1.7727 - val_accuracy: 0.3030\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7134 - accuracy: 0.3320 - val_loss: 1.7830 - val_accuracy: 0.2929\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7134 - accuracy: 0.3310 - val_loss: 1.7848 - val_accuracy: 0.2828\n",
      "78/78 [==============================] - 0s 2ms/step\n",
      "RMSE for MLP:  0.7545223161287015\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "# MLP\n",
    "K.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(256, activation='sigmoid', input_shape=(train_data_normalized.shape[1],)))\n",
    "model.add(keras.layers.Dense(128, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(64, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(32, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(len(tags), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_data_normalized, trainY_labels, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "predMLP = model.predict(train_data_normalized)\n",
    "predMLP = np.argmax(predMLP, axis=1)\n",
    "predMLP = [tags[i] for i in predMLP]\n",
    "print(\"RMSE for MLP: \", sqrt(metrics.mean_squared_error(trainY, predMLP)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value for SVM:  {'C': 1000.0, 'gamma': 0.1}\n",
      "RMSE for SVM:  0.7200094428087114\n"
     ]
    }
   ],
   "source": [
    "# SVM with rbf kernel, Cross Validation\n",
    "paramgrid = {'C': logspace(-3, 3, 7), \n",
    "             'gamma': logspace(-3, 3, 7)}\n",
    "\n",
    "svmcv = model_selection.GridSearchCV(estimator=svm.SVC(kernel='rbf'),\n",
    "                                        param_grid=paramgrid, cv=5)\n",
    "svmcv.fit(train_data_normalized, trainY_labels)\n",
    "\n",
    "predSVM = svmcv.predict(train_data_normalized)\n",
    "predSVM = [tags[i] for i in predSVM]\n",
    "print(\"Best C value for SVM: \", svmcv.best_params_)\n",
    "print(\"RMSE for SVM: \", sqrt(metrics.mean_squared_error(trainY, predSVM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification shows bad results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for LGBM:  0.4793492626383126\n"
     ]
    }
   ],
   "source": [
    "# LGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(train_data_normalized, trainY)\n",
    "predLGBM = lgbm.predict(train_data_normalized)\n",
    "print(\"RMSE for LGBM: \", sqrt(metrics.mean_squared_error(trainY, predLGBM)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is good. But when we submit the result to Kaggle, the score is not good. Even worse than the kernel RR regression. This may be because of the overfitting.\n",
    "\n",
    "So we can try to tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for LGBM:  0.5517463801586462\n"
     ]
    }
   ],
   "source": [
    "param = {'n_estimators': 512,\n",
    "         'learning_rate': 0.01,\n",
    "         'metric': 'rmse',\n",
    "         'random_state': 42,\n",
    "         'force_col_wise': True,\n",
    "         'verbosity': 0,}\n",
    "lgbm = LGBMRegressor(**param)\n",
    "lgbm.fit(train_data_normalized, trainY)\n",
    "predLGBM = lgbm.predict(train_data_normalized)\n",
    "print(\"RMSE for LGBM: \", sqrt(metrics.mean_squared_error(trainY, predLGBM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN in test_data_normalized by 0\n",
    "test_data_normalized = np.nan_to_num(test_data_normalized)\n",
    "predY = krrcv.predict(test_data_normalized)\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_data_representation.index\n",
    "submission['score'] = predY\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
