{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from numpy import *\n",
    "import re\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_movedis_movelength(row):\n",
    "    if re.search(r'Move From \\[(\\d+), (\\d+)\\] To \\[(\\d+), (\\d+)\\]', row['activity']):\n",
    "        match = re.search(r'Move From \\[(\\d+), (\\d+)\\] To \\[(\\d+), (\\d+)\\]', row['activity'])\n",
    "        x1, y1, x2, y2 = map(int, match.groups())\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        dis = abs(x2 - x1)\n",
    "        length = (y1 - x1)\n",
    "    else:\n",
    "        dis = 0\n",
    "        length = 0\n",
    "    return dis, length\n",
    "\n",
    "def set_pastelength(row):\n",
    "    if row['activity'] == 'Paste':\n",
    "        return len(row['text_change'])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def set_replacelength(row):\n",
    "    if row['activity'] == 'Replace':\n",
    "        replace_text = row['text_change']\n",
    "        before_text, after_text = replace_text.split(' => ')\n",
    "\n",
    "        before_length = len(before_text)\n",
    "        after_length = len(after_text)\n",
    "\n",
    "        return before_length - after_length\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def set_RClength(row):\n",
    "    if row['activity'] == 'Remove/Cut':\n",
    "        text_change = row['text_change']\n",
    "        return len(text_change)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "Keyboard_keywords = ['Leftclick', 'Shift', 'Backspace', 'Enter', 'ArrowLeft', 'ArrowRight', 'Tab', 'ArrowUp', 'ArrowDown', 'Rightclick',\n",
    "           'CapsLock', 'Control', 'Delete', 'Home', 'End', 'Insert', 'NumLock', 'Alt',\n",
    "           'ContextMenu','PageDown', 'Middleclick', 'ScrollLock', 'Space',\n",
    "           'Cancel', 'Escape', 'Clear', 'OS']\n",
    "for i in range(1,16):\n",
    "  Keyboard_keywords.append('F'+str(i))#F1--F15\n",
    "Media_keywords = ['Meta','AudioVolumeMute','MediaPlayPause','AudioVolumeUp','AudioVolumeDown','MediaTrackPrevious', 'MediaTrackNext', 'Pause']\n",
    "Other_keywords = ['Dead', 'Process', 'AltGraph',]\n",
    "Unknown_keywords = ['Unidentified','Unknownclick']\n",
    "\n",
    "def convert_down_event_char(value):\n",
    "    if len(value) == 1 and (value.isalpha() or value.isdigit()):\n",
    "        return 'q'\n",
    "    elif value in Keyboard_keywords:\n",
    "        return \"keyboard_keyword\"\n",
    "    elif value in Media_keywords:\n",
    "        return \"media_keyword\"\n",
    "    elif value in Other_keywords:\n",
    "        return \"other_keyword\"\n",
    "    elif value in Unknown_keywords:\n",
    "        return \"unknown_keyword\"\n",
    "    else:\n",
    "        return \"unknown_keyword\"\n",
    "\n",
    "actype = {0:'Nonproduction',\n",
    "      1:'Input',\n",
    "      2:'Remove/Cut',\n",
    "      3:'Paste',\n",
    "      4:'Replace',\n",
    "      5:'Move'\n",
    "      }\n",
    "\n",
    "def set_activity(row):\n",
    "    if row['activity'] == 'Nonproduction':\n",
    "        return 0\n",
    "    elif row['activity'] == 'Input':\n",
    "        return 1\n",
    "    elif row['activity'] == 'Remove/Cut':\n",
    "        return 2\n",
    "    elif row['activity'] == 'Paste':\n",
    "        return 3\n",
    "    elif row['activity'] == 'Replace':\n",
    "        return 4\n",
    "    else:\n",
    "      return 5\n",
    "def preprocess(df):\n",
    "\n",
    "  df.sort_values(by=['id', 'event_id'])\n",
    "\n",
    "  df['delta_cursor'] = (df['cursor_position'] - df['cursor_position'].shift(1))\n",
    "  df.loc[0, 'delta_cursor'] = 0\n",
    "\n",
    "  df['movedis'], df['movelength'] = zip(*df.apply(set_movedis_movelength, axis=1))\n",
    "\n",
    "  df['pastelength'] = df.apply(set_pastelength, axis=1)\n",
    "\n",
    "  df['replacelength'] = df.apply(set_replacelength, axis=1)\n",
    "\n",
    "  df['RClength'] = df.apply(set_RClength, axis=1)\n",
    "\n",
    "  df['keyword'] = df['down_event'].apply(convert_down_event_char)\n",
    "\n",
    "  df['actype'] = df.apply(set_activity,axis=1)\n",
    "\n",
    "  df['thinktime'] = df['down_time'] - df['up_time'].shift()\n",
    "  df['thinktime'] = df['thinktime'].clip(lower=0)\n",
    "\n",
    "  df['contype'] = (df['down_time'] <= df['up_time'].shift()).astype(int)\n",
    "\n",
    "  df.drop([\"up_event\", \"activity\", \"down_event\", \"text_change\", \"cursor_position\"], axis=1, inplace=True)\n",
    "def getfeature(df,data):\n",
    "  consecutive_input_lengths = []\n",
    "  for id_value, group in tqdm(df.groupby('id')):\n",
    "    #print(id_value)\n",
    "    word_count = group['word_count'].iloc[-1]\n",
    "\n",
    "    contype_count = group['contype'].eq(1).sum()\n",
    "\n",
    "    total_think = group['thinktime'].sum()\n",
    "\n",
    "    total_time = group['up_time'].iloc[-1] - group['down_time'].iloc[0]\n",
    "\n",
    "    action_count = group.shape[0]\n",
    "\n",
    "    total_actiontime = group['action_time'].sum()\n",
    "\n",
    "    keyword_counts = group['keyword'].value_counts()\n",
    "    keyboard_count = keyword_counts.get('keyboard_keyword', 0)\n",
    "    media_count = keyword_counts.get('media_keyword', 0)\n",
    "    other_count = keyword_counts.get('other_keyword', 0)\n",
    "    unknown_count = keyword_counts.get('unknown_keyword', 0)\n",
    "\n",
    "    delta_cursor = group['delta_cursor']\n",
    "    dc0 = delta_cursor.between(0, 1).sum()\n",
    "    dc1 = delta_cursor.between(2, 10).sum()\n",
    "    dc2 = delta_cursor.between(11, 30).sum()\n",
    "    dc3 = delta_cursor.between(31, 80).sum()\n",
    "    dc4 = (delta_cursor > 80).sum()\n",
    "    dc5 = delta_cursor.between(-1, -1).sum()\n",
    "    dc6 = delta_cursor.between(-10, -2).sum()\n",
    "    dc7 = delta_cursor.between(-30, -11).sum()\n",
    "    dc8 = delta_cursor.between(-80, -31).sum()\n",
    "    dc9 = (delta_cursor < -80).sum()\n",
    "\n",
    "    movedis = group['movedis']\n",
    "    md0 = movedis.between(0, 1).sum()\n",
    "    md1 = movedis.between(2, 10).sum()\n",
    "    md2 = movedis.between(11, 30).sum()\n",
    "    md3 = movedis.between(31, 80).sum()\n",
    "    md4 = (movedis > 80).sum()\n",
    "\n",
    "    movelength = group['movelength']\n",
    "    ml0 = movelength.between(0, 5).sum()\n",
    "    ml1 = movelength.between(6, 15).sum()\n",
    "    ml2 = movelength.between(16, 30).sum()\n",
    "    ml3 = movelength.between(31, 80).sum()\n",
    "    ml4 = (movelength > 80).sum()\n",
    "\n",
    "    pastelength = group['pastelength']\n",
    "    pl0 = pastelength.between(0, 1).sum()\n",
    "    pl1 = pastelength.between(2, 10).sum()\n",
    "    pl2 = pastelength.between(11, 30).sum()\n",
    "    pl3 = pastelength.between(31, 80).sum()\n",
    "    pl4 = (pastelength > 80).sum()\n",
    "\n",
    "    replacelength = group['replacelength']\n",
    "    rl0 = replacelength.between(0, 1).sum()\n",
    "    rl1 = replacelength.between(2, 10).sum()\n",
    "    rl2 = replacelength.between(11, 30).sum()\n",
    "    rl3 = replacelength.between(31, 80).sum()\n",
    "    rl4 = (replacelength > 80).sum()\n",
    "\n",
    "    RClength = group['RClength']\n",
    "    rc0 = RClength.between(0, 1).sum()\n",
    "    rc1 = RClength.between(2, 10).sum()\n",
    "    rc2 = RClength.between(11, 30).sum()\n",
    "    rc3 = RClength.between(31, 80).sum()\n",
    "    rc4 = (RClength > 80).sum()\n",
    "\n",
    "    actype_counts = group['actype'].value_counts()\n",
    "    ac0 = actype_counts.get(0, 0)\n",
    "    ac1 = actype_counts.get(1, 0)\n",
    "    ac2 = actype_counts.get(2, 0)\n",
    "    ac3 = actype_counts.get(3, 0)\n",
    "    ac4 = actype_counts.get(4, 0)\n",
    "    ac5 = actype_counts.get(5, 0)\n",
    "\n",
    "    '''consecutive_input = np.where(\n",
    "        (group['actype'] == 1) & (group['actype'].shift(1) != 1), 1, 0\n",
    "    )\n",
    "    consecutive_input_count = consecutive_input.sum()'''\n",
    "\n",
    "    consecutive_input_count = 0\n",
    "    consecutive_input_lengths = [1]\n",
    "    prev_action_type = None\n",
    "    for index, row in group.iterrows():\n",
    "      current_action_type = row['actype']\n",
    "      if prev_action_type == 1 and current_action_type != 1:\n",
    "          consecutive_input_count += 1\n",
    "          consecutive_input_lengths.append(0)\n",
    "      elif prev_action_type == 1 and current_action_type == 1:\n",
    "          consecutive_input_lengths[-1] += 1\n",
    "      prev_action_type = current_action_type\n",
    "\n",
    "    consecutive_input_max = max(consecutive_input_lengths)\n",
    "    consecutive_input_mean = np.mean(consecutive_input_lengths)\n",
    "    consecutive_input_median = np.median(consecutive_input_lengths)\n",
    "    consecutive_input_variance = np.var(consecutive_input_lengths)\n",
    "\n",
    "    data = data._append(\n",
    "        {\n",
    "            'id': id_value,\n",
    "            'word_count': word_count,\n",
    "            'contype_count': contype_count,\n",
    "            'total_think': total_think,\n",
    "            'total_time': total_time,\n",
    "            'action_count': action_count,\n",
    "            'total_actiontime': total_actiontime,\n",
    "            'keyboard_count': keyboard_count,\n",
    "            'media_count': media_count,\n",
    "            'other_count': other_count,\n",
    "            'unknown_count': unknown_count,\n",
    "            'dc0': dc0,\n",
    "            'dc1': dc1,\n",
    "            'dc2': dc2,\n",
    "            'dc3': dc3,\n",
    "            'dc4': dc4,\n",
    "            'dc5': dc5,\n",
    "            'dc6': dc6,\n",
    "            'dc7': dc7,\n",
    "            'dc8': dc8,\n",
    "            'dc9': dc9,\n",
    "            'md0': md0,\n",
    "            'md1': md1,\n",
    "            'md2': md2,\n",
    "            'md3': md3,\n",
    "            'md4': md4,\n",
    "            'ml0': ml0,\n",
    "            'ml1': ml1,\n",
    "            'ml2': ml2,\n",
    "            'ml3': ml3,\n",
    "            'ml4': ml4,\n",
    "            'pl0': pl0,\n",
    "            'pl1': pl1,\n",
    "            'pl2': pl2,\n",
    "            'pl3': pl3,\n",
    "            'pl4': pl4,\n",
    "            'rl0': rl0,\n",
    "            'rl1': rl1,\n",
    "            'rl2': rl2,\n",
    "            'rl3': rl3,\n",
    "            'rl4': rl4,\n",
    "            'rc0': rc0,\n",
    "            'rc1': rc1,\n",
    "            'rc2': rc2,\n",
    "            'rc3': rc3,\n",
    "            'rc4': rc4,\n",
    "            'ac0': ac0,\n",
    "            'ac1': ac1,\n",
    "            'ac2': ac2,\n",
    "            'ac3': ac3,\n",
    "            'ac4': ac4,\n",
    "            'ac5': ac5,\n",
    "            'consecutive_input_count': consecutive_input_count,\n",
    "            'consecutive_input_max': consecutive_input_max,\n",
    "            'consecutive_input_mean': consecutive_input_mean,\n",
    "            'consecutive_input_mid': consecutive_input_median,\n",
    "            'consecutive_input_var': consecutive_input_variance,\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = pd.read_csv('train_logs.csv')\n",
    "test_logs = pd.read_csv('test_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preprocess(train_logs)\n",
    "preprocess(test_logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainX = pd.DataFrame()\n",
    "testX = pd.DataFrame()\n",
    "\n",
    "trainX = getfeature(train_logs,trainX)\n",
    "testX = getfeature(test_logs,testX)\n",
    "\n",
    "train_scores = pd.read_csv('train_scores.csv')\n",
    "trainY = train_scores['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.drop(['id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "# apply normalization techniques\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "trainX = np.nan_to_num(trainX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramgrid = {'alpha': logspace(-6, 0, 10), \n",
    "             'gamma': logspace(-6, 0, 10)}\n",
    "\n",
    "krrcv = model_selection.GridSearchCV(estimator=kernel_ridge.KernelRidge(kernel='rbf'),\n",
    "                                      param_grid=paramgrid, cv=5)\n",
    "krrcv.fit(trainX, trainY)\n",
    "\n",
    "# print the RMSE for the best alpha value\n",
    "print(\"Best alpha value for Kernel Ridge Regression: \", krrcv.best_params_)\n",
    "print(\"RMSE for Kernel Ridge Regression: \", sqrt(metrics.mean_squared_error(trainY, krrcv.predict(trainX))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(trainX, trainY)\n",
    "print(\"RMSE for LightGBM: \", sqrt(metrics.mean_squared_error(trainY, lgbm.predict(trainX))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
